{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590c6424-a313-4835-860b-da82bbdd8554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import network\n",
    "import guided_filter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import io\n",
    "import uvicorn\n",
    "import nest_asyncio\n",
    "from enum import Enum\n",
    "from fastapi import FastAPI, UploadFile, File, HTTPException, Request, responses\n",
    "from fastapi.responses import StreamingResponse, HTMLResponse\n",
    "from fastapi.templating import Jinja2Templates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee39709-fa20-4808-b8f3-006cdaaaee42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_crop(image):\n",
    "    h, w, c = np.shape(image)\n",
    "    if min(h, w) > 720:\n",
    "        if h > w:\n",
    "            h, w = int(720*h/w), 720\n",
    "        else:\n",
    "            h, w = 720, int(720*w/h)\n",
    "    image = cv2.resize(image, (w, h), interpolation=cv2.INTER_AREA)\n",
    "    h, w = (h//8)*8, (w//8)*8\n",
    "    image = image[:h, :w, :]\n",
    "    return image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6859ce4b-10af-47c5-a7d8-5b503fdfa336",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'saved_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745caed6-1d5d-4b5f-857c-e1c900665919",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = \"images_uploaded\"\n",
    "if not os.path.exists(dir_name):\n",
    "    os.mkdir(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0456e32-7d27-4ac9-b05a-31a6200d96cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_cartonizer(model_path):\n",
    "    \n",
    "    input_photo = tf.placeholder(tf.float32, [1, None, None, 3])\n",
    "    network_out = network.unet_generator(input_photo)\n",
    "    final_out = guided_filter.guided_filter(input_photo, network_out, r=1, eps=5e-3)\n",
    "\n",
    "    all_vars = tf.trainable_variables()\n",
    "    gene_vars = [var for var in all_vars if 'generator' in var.name]\n",
    "    saver = tf.train.Saver(var_list=gene_vars)\n",
    "    \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(model_path))\n",
    "    return sess,final_out,input_photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4107ec-a386-46ab-8668-1487da4fa9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_cartoon(sess,image,final_out,input_photo):\n",
    "    \n",
    "    try:\n",
    "        image = resize_crop(image)\n",
    "        batch_image = image.astype(np.float32)/127.5 - 1\n",
    "        batch_image = np.expand_dims(batch_image, axis=0)\n",
    "        output = sess.run(final_out, feed_dict={input_photo: batch_image})\n",
    "        output = (np.squeeze(output)+1)*127.5\n",
    "        output = np.clip(output, 0, 255).astype(np.uint8)\n",
    "    \n",
    "        return output\n",
    "    except:\n",
    "        print('cartoonize {} failed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8736b87-1e1a-487d-ad75-f46edd4f0d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess,final_out,input_photo=new_cartonizer(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcb7905-d7dc-4e5b-a749-400f9d90e3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign an instance of the FastAPI class to the variable \"app\".\n",
    "# You will interact with your api using this instance.\n",
    "app = FastAPI(title='Deploying a ML Model with FastAPI')\n",
    "# By using @app.get(\"/\") you are allowing the GET method to work for the / endpoint.\n",
    "\n",
    "@app.get(\"/\")\n",
    "def home():\n",
    "    return \"Welcome to my Cartoon World\"\n",
    "\n",
    "@app.post(\"/cartoonize\")\n",
    "def cartoonize(file: UploadFile = File(...)):\n",
    "   \n",
    "    # 1. VALIDATE INPUT FILE\n",
    "    filename = file.filename\n",
    "    fileExtension = filename.split(\".\")[-1] in (\"jpg\", \"jpeg\", \"png\")\n",
    "    if not fileExtension:\n",
    "        raise HTTPException(status_code=415, detail=\"Unsupported file provided.\")\n",
    "    \n",
    "    # 2. TRANSFORM RAW IMAGE INTO CV2 imag\n",
    "    # Read image as a stream of bytes\n",
    "    image_stream = io.BytesIO(file.file.read())\n",
    "    # Start the stream from the beginning (position zero)\n",
    "    image_stream.seek(0)\n",
    "    # Write the stream of bytes into a numpy array\n",
    "    file_bytes = np.asarray(bytearray(image_stream.read()), dtype=np.uint8)\n",
    "    # Decode the numpy array as an image\n",
    "    image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    # 3. RUN Cartoonization algorithm\n",
    "    # Create cartoonized image\n",
    "    output_image = new_cartoon(sess,image,final_out,input_photo)\n",
    "    # Save it in a folder within the server\n",
    "    cv2.imwrite(f'images_uploaded/{filename}', image)\n",
    "    cv2.imwrite(f'images_uploaded/cartoon_{filename}', output_image)\n",
    "    \n",
    "    # 4. STREAM THE RESPONSE BACK TO THE CLIENT \n",
    "    # Open the saved image for reading in binary mode\n",
    "    file_image2 = open(f'images_uploaded/cartoon_{filename}', mode=\"rb\")\n",
    "    file_image = open(f'images_uploaded/{filename}', mode=\"rb\")\n",
    "    \n",
    "    # Return the image as a stream specifying media type\n",
    "    return StreamingResponse(file_image2, media_type=\"image/jpeg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dacff6-10a3-4d75-83ab-c75e0bcd1f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows the server to be run in this interactive environment\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Host depends on the setup you selected (docker or virtual env)\n",
    "host = \"0.0.0.0\" if os.getenv(\"DOCKER-SETUP\") else \"127.0.0.1\"\n",
    "\n",
    "# Spin up the server!    \n",
    "uvicorn.run(app, host=host, port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69305f2c-a8c7-443f-b1da-3b2a27f2d4de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29cfd530-df90-4075-ab3c-00ffe08bcf80",
   "metadata": {},
   "source": [
    "\n",
    "# Bonus video processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c94df8-2b90-460e-a029-74c279fe89a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import IPython.display as ipd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import subprocess\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de63598b-387e-41ad-b6cf-662c190cb4be",
   "metadata": {},
   "source": [
    "## Display video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d21ccf5-48cd-4f25-811a-acc630ae1df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Video('videoName.mp4', width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ff27b8-24cc-4cfd-8d86-d349549f22ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in video capture\n",
    "cap = cv2.VideoCapture('videoName.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dc24a5-d4d0-4245-b211-27410a359c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of frames in video\n",
    "cap.get(cv2.CAP_PROP_FRAME_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898c6c35-10e4-438a-bb3b-3c06d6f07f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video height and width\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "print(f'Height {height}, Width {width}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666b72c6-01ec-4a59-b94a-37c1d670a5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get frames per second\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(f'FPS : {fps:0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73b3f1e-f6eb-45a6-84cc-e2fdef14b4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d609950-6ce2-452b-bff6-cb665060fb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper function for plotting opencv images in notebook\n",
    "def display_cv2_img(img, figsize=(10, 10)):\n",
    "    img_ = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(img_)\n",
    "    ax.axis(\"off\")\n",
    "    return img_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185fd87c-8833-417b-8547-41fb75f2177b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e6ed89-ba5d-4d71-b0c0-87e3e9f81e78",
   "metadata": {},
   "source": [
    "### Display multiple frams from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b521c0ce-9f15-4d27-9e20-b0f41ee99ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(\"videoName.mp4\")\n",
    "n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(30, 20))\n",
    "axs = axs.flatten()\n",
    "\n",
    "img_idx = 0\n",
    "for frame in range(n_frames):\n",
    "    ret, img = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    if frame % 100 == 0:\n",
    "        axs[img_idx].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        axs[img_idx].set_title(f'Frame: {frame}')\n",
    "        axs[img_idx].axis('off')\n",
    "        img_idx += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aef8c4-8309-45db-bf8e-eb9240376070",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess,final_out,input_photo=new_cartonize(save_folder, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3010b033-9ec2-4253-89ed-ffe070c46451",
   "metadata": {},
   "source": [
    "## cartoonizing the whole video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faf034c-697e-459f-a60d-1eb73db71a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = \"cartoon_video\"\n",
    "if not os.path.exists(dir_name):\n",
    "    os.mkdir(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5a1e87-efaf-4753-929a-f07ef170e4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(\"videoName.mp4\")\n",
    "n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "VIDEO_CODEC = \"mp4v\"\n",
    "img=cv2.imread(f'{0}.jpg')\n",
    "height,width,layers=img.shape\n",
    "size=(width,height)\n",
    "out = cv2.VideoWriter(\"videoName_cartoon.mp4\", cv2.VideoWriter_fourcc(*VIDEO_CODEC), n_frames, size)\n",
    "out.write(img)\n",
    "\n",
    "sess,final_out,input_photo=new_cartonize(save_folder, model_path)\n",
    "os.chdir(r\"cartoon_video\")\n",
    "\n",
    "for frame in tqdm(range(n_frames//2), total=n_frames//2):\n",
    "    ret, img = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    img = new_cartoon(sess,img, final_out, input_photo)\n",
    "    out.write(img)\n",
    "    \n",
    "out.release()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcf7bfc-b343-4d50-8458-85d0ff1c25d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Video('videoName_cartoon.mp4', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaa1971-7e55-4cfb-ba68-e674e500b5f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
